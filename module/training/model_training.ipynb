{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import librairies\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset found in Kaggle.com\n",
    "data = pd.read_csv('dataset/stock_market_comments.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change -1 to 0 (all negative sentiments)\n",
    "data.Sentiment = data.Sentiment.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar plot \n",
    "x = ['Negative', 'Positive']\n",
    "y = [data[data['Sentiment'] == 0].shape[0], data[data['Sentiment'] == 1].shape[0]]\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "        \"\"\"Preprocess comments with different techniques to transform them \n",
    "        \n",
    "        into a more predictable form for the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : Dataframe \n",
    "             The comments to be preprocessed.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        df : dataframe with new cleaned text column\n",
    "        \"\"\"\n",
    "        clean_text_list = []\n",
    "        stemmer = PorterStemmer() \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        \n",
    "\n",
    "        for i in range(len(df.axes[0])):\n",
    "\n",
    "            # Lowercasing, removing digits and non alphabetic characters\n",
    "            text = str(df['Text'][i]).lower().replace('{html}',\"\") \n",
    "            cleanr = re.compile('<.*?>')\n",
    "            clean_text = re.sub(cleanr, '', text)\n",
    "            rem_url = re.sub(r'http\\S+', '', clean_text)\n",
    "            rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "\n",
    "            #Tokenization\n",
    "            tokens = tokenizer.tokenize(rem_num)  \n",
    "\n",
    "            #Removing stop words\n",
    "            filtered_words = [w for w in tokens if not w in stopwords_list]\n",
    "\n",
    "            #Stemming\n",
    "            stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "\n",
    "            #Lemming\n",
    "            lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "\n",
    "            clean_text = \" \".join(lemma_words)\n",
    "            clean_text_list.append(clean_text)            \n",
    "        \n",
    "        df['cleaned text'] = clean_text_list\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df):\n",
    "        \"\"\"Convert cleaned comments to a matrix of TF-IDF numerical features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : Dataframe \n",
    "             The comments to be vectorized.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        vectorized_text : 2D list of features to feed to model\n",
    "        \"\"\"\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        pca = PCA(n_components=150) \n",
    "        vectorized_text = vectorizer.fit_transform(df['cleaned text']).toarray()\n",
    "        vectorized_text = pca.fit_transform(vectorized_text) # fits columns to 150\n",
    "        \n",
    "        #Save vectorizer\n",
    "        pkl_filename = \"Tfidf_Vectorizer.pkl\"\n",
    "        with open(pkl_filename, 'wb') as file:\n",
    "            pickle.dump(vectorizer, file)\n",
    "        \n",
    "        #Save pca\n",
    "        pkl_filename = \"pca.pkl\"\n",
    "        with open(pkl_filename, 'wb') as file:\n",
    "            pickle.dump(pca, file)\n",
    "        \n",
    "        return vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess data\n",
    "data = preprocess_text(data)\n",
    "x = vectorize(data)\n",
    "y = data[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train/test data\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model and predict test set\n",
    "model_SVC = SVC(kernel='linear', probability=True)\n",
    "model_SVC.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model_SVC.predict(x_test)\n",
    "print(\"{} Accuracy: {}\".format(\"svc\",accuracy_score(y_test,y_pred)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "pkl_filename = \"sentimentw_svm_model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model_SVC, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('ml_env': conda)",
   "language": "python",
   "name": "python38364bitmlenvcondafbb694900e93483999a77c876c10f57e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
